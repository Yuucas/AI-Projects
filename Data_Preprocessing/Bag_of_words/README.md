# Bag of Words (BoW)
Bag of Words is a simple yet effective technique for converting text data into numerical representations that machine learning algorithms can understand.

<p align="center">
  <img width="600" src="https://github.com/Yuucas/NLP/blob/3091c02973960e3990faafe931b22eafb5681ffb/Data_Preprocessing/Bag_of_words/table.png"></a>
</p>
<div align="center">


<div align="left">
  
### How it works:
* **Tokenization:** The text is divided into individual words (tokens).
* **Vocabulary Creation:** A unique list of all words in the text corpus is created. This is called the vocabulary.
* **Vectorization:** Each document is represented as a numerical vector, where each element corresponds to a word in the vocabulary. The element's value represents the frequency of that word in the document.
